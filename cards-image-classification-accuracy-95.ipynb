{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4532039,"sourceType":"datasetVersion","datasetId":2579480}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Cards Image Classification \n### Building Classification Model From Scratch using pytorch ","metadata":{}},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:09:47.393610Z","iopub.execute_input":"2024-05-21T18:09:47.393990Z","iopub.status.idle":"2024-05-21T18:09:53.788919Z","shell.execute_reply.started":"2024-05-21T18:09:47.393960Z","shell.execute_reply":"2024-05-21T18:09:53.787625Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os, shutil, numpy as np\nfrom glob import glob\nfrom PIL import Image\nfrom torch.utils.data import random_split, Dataset, DataLoader\nfrom torchvision import transforms as T\ntorch.manual_seed(2024)\n\nclass CustomDataset(Dataset):\n    def __init__(self, root, data, transformations = None):\n        self.transformations = transformations\n        self.im_paths = sorted(glob(f\"{root}/{data}/*/*\"))\n        self.cls_names, self.cls_counts, count, data_count = {}, {}, 0, 0\n        \n        for idx, im_path in enumerate(self.im_paths):\n            class_name = self.get_class(im_path)\n            if class_name not in self.cls_names: \n                self.cls_names[class_name] = count\n                self.cls_counts[class_name] = 1\n                count += 1\n            else: \n                self.cls_counts[class_name] += 1\n        \n    def get_class(self, path): \n        return os.path.dirname(path).split(\"/\")[-1]\n    \n    def __len__(self): \n        return len(self.im_paths)\n\n    def __getitem__(self, idx):\n        im_path = self.im_paths[idx]\n        im = Image.open(im_path).convert(\"RGB\")\n        gt = self.cls_names[self.get_class(im_path)]\n        if self.transformations is not None: \n            im = self.transformations(im)\n        return im, gt\n    \ndef get_dls(root, transformations, bs, split = [0.9, 0.05, 0.05], ns = 4):\n    \n    tr_ds = CustomDataset(root = root, data = \"train\", transformations = transformations)\n    vl_ds = CustomDataset(root = root, data = \"valid\",transformations = transformations)\n    ts_ds = CustomDataset(root = root, data = \"test\",transformations = transformations)\n    \n    tr_dl, val_dl, ts_dl = DataLoader(tr_ds, batch_size = bs, shuffle = True, num_workers = ns,pin_memory=True), DataLoader(vl_ds, batch_size = bs, shuffle = False, num_workers = ns), DataLoader(ts_ds, batch_size = 1, shuffle = False, num_workers = ns,pin_memory=True)\n    \n    return tr_dl, val_dl, ts_dl, tr_ds.cls_names\n\nroot = \"/kaggle/input/cards-image-datasetclassification\"\nmean, std, im_size = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 224\ntfs = T.Compose([T.Resize((im_size, im_size)), T.ToTensor(), T.Normalize(mean = mean, std = std)])\ntr_dl, val_dl, ts_dl, classes = get_dls(root = root, transformations = tfs, bs = 36)\n\nprint(len(tr_dl)); print(len(val_dl)); print(len(ts_dl)); print(classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:09:53.790861Z","iopub.execute_input":"2024-05-21T18:09:53.791314Z","iopub.status.idle":"2024-05-21T18:09:55.573051Z","shell.execute_reply.started":"2024-05-21T18:09:53.791284Z","shell.execute_reply":"2024-05-21T18:09:55.572020Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"212\n8\n265\n{'ace of clubs': 0, 'ace of diamonds': 1, 'ace of hearts': 2, 'ace of spades': 3, 'eight of clubs': 4, 'eight of diamonds': 5, 'eight of hearts': 6, 'eight of spades': 7, 'five of clubs': 8, 'five of diamonds': 9, 'five of hearts': 10, 'five of spades': 11, 'four of clubs': 12, 'four of diamonds': 13, 'four of hearts': 14, 'four of spades': 15, 'jack of clubs': 16, 'jack of diamonds': 17, 'jack of hearts': 18, 'jack of spades': 19, 'joker': 20, 'king of clubs': 21, 'king of diamonds': 22, 'king of hearts': 23, 'king of spades': 24, 'nine of clubs': 25, 'nine of diamonds': 26, 'nine of hearts': 27, 'nine of spades': 28, 'queen of clubs': 29, 'queen of diamonds': 30, 'queen of hearts': 31, 'queen of spades': 32, 'seven of clubs': 33, 'seven of diamonds': 34, 'seven of hearts': 35, 'seven of spades': 36, 'six of clubs': 37, 'six of diamonds': 38, 'six of hearts': 39, 'six of spades': 40, 'ten of clubs': 41, 'ten of diamonds': 42, 'ten of hearts': 43, 'ten of spades': 44, 'three of clubs': 45, 'three of diamonds': 46, 'three of hearts': 47, 'three of spades': 48, 'two of clubs': 49, 'two of diamonds': 50, 'two of hearts': 51, 'two of spades': 52}\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomCNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n        self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(256 * 28 * 28, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, num_classes)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.pool_2(self.relu(self.conv1(x)))\n        x = self.relu(self.conv2(x))\n        x = self.pool_2(self.relu(self.conv3(x)))\n        x = self.relu(self.conv4(x))\n        x = self.pool_2(self.relu(self.conv5(x)))\n        x = x.view(-1, 256 * 28 * 28)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:09:55.574495Z","iopub.execute_input":"2024-05-21T18:09:55.574905Z","iopub.status.idle":"2024-05-21T18:09:55.585862Z","shell.execute_reply.started":"2024-05-21T18:09:55.574869Z","shell.execute_reply":"2024-05-21T18:09:55.584666Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nmodel = CustomCNN(num_classes=53) \n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:09:55.588262Z","iopub.execute_input":"2024-05-21T18:09:55.588610Z","iopub.status.idle":"2024-05-21T18:09:56.815632Z","shell.execute_reply.started":"2024-05-21T18:09:55.588582Z","shell.execute_reply":"2024-05-21T18:09:56.814648Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"CustomCNN(\n  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=200704, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=53, bias=True)\n  (relu): ReLU()\n)"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Train the model\nnum_epochs = 30\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()  # training mode\n    running_loss = 0.0\n    \n    # Wrap the training data loader with tqdm\n    with tqdm(total=len(tr_dl)) as pbar:\n        for i, (inputs, labels) in enumerate(tr_dl, 0):\n            optimizer.zero_grad()  # Zero the parameter gradients\n\n            # Forward pass\n            outputs = model(inputs.to(device))\n        \n            # Calculate loss\n            loss = criterion(outputs, labels.to(device))\n        \n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            # Update tqdm progress bar\n            pbar.update(1)\n            pbar.set_description(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {running_loss / (i + 1):.4f}\")\n\n    # Validation phase\n    model.eval()  # evaluation mode\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in val_dl:\n            outputs = model(inputs.to(device))\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels.to(device)).sum().item()\n\n    # Calculate accuracy\n    val_accuracy = correct / total\n\n    # Print statistics\n    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n          f'Training Loss: {running_loss / len(tr_dl):.4f}, '\n          f'Validation Accuracy: {100 * val_accuracy:.2f}%')\n\nprint('Finished Training')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:26:28.099762Z","iopub.execute_input":"2024-05-21T18:26:28.100142Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch [1/30], Training Loss: 1.9433: 100%|██████████| 212/212 [19:08<00:00,  5.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/30], Training Loss: 1.9433, Validation Accuracy: 69.06%\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/30], Training Loss: 1.0802: 100%|██████████| 212/212 [19:30<00:00,  5.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/30], Training Loss: 1.0802, Validation Accuracy: 80.38%\n","output_type":"stream"},{"name":"stderr","text":"Epoch [3/30], Training Loss: 0.5576:  66%|██████▌   | 139/212 [14:10<07:49,  6.44s/it]","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in ts_dl:\n        images, labels = data\n        outputs = model(images.to(device))\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels.to(device)).sum().item()\n\nprint('Accuracy on the test images: %d %%' % (100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:26:26.971678Z","iopub.status.idle":"2024-05-21T18:26:26.972097Z","shell.execute_reply.started":"2024-05-21T18:26:26.971904Z","shell.execute_reply":"2024-05-21T18:26:26.971924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transfer Learning Methods Using ResNet18 Model","metadata":{}},{"cell_type":"markdown","source":"Transfer learning is a machine learning technique where a model trained on one task is reused as the starting point for a model on a second task. Instead of training a model from scratch, which can be time-consuming and computationally expensive, transfer learning leverages knowledge gained from solving one problem and applies it to a different but related problem.\n\n1. **Pre-trained Model**: Start with a model that has been trained on a large dataset for a specific task, such as image classification. This model has learned to extract general features from the data that are useful for solving that task.\n\n2. **Task-Specific Adaptation**: Instead of training the model from scratch, you adapt the pre-trained model to your specific task by fine-tuning it on a smaller dataset related to the new task. This process involves adjusting the model's parameters to better fit the new data while retaining the valuable knowledge learned during the initial training.\n\nTransfer learning is especially useful when you have a limited amount of data for your target task or when training a model from scratch would be impractical due to resource constraints.\n\nResNet, short for Residual Network, is a specific type of deep neural network architecture that was introduced to address the problem of vanishing gradients during training. The vanishing gradient problem occurs when gradients become extremely small as they propagate backward through many layers of a neural network, making it difficult to train deep networks effectively.\n\n**ResNet** introduces a concept called residual learning, where each layer in the network learns to predict the residual between the input and the output of the layer, rather than directly trying to learn the desired underlying mapping. This is achieved through the use of skip connections, also known as shortcut connections or identity mappings, which allow gradients to bypass certain layers. These connections enable the network to learn residual functions effectively, making it easier to train very deep neural networks.\n\nThe key innovation of ResNet is the residual block, which consists of a set of layers with a skip connection that adds the input to the output of the block. By adding these skip connections, ResNet can effectively train extremely deep networks with hundreds or even thousands of layers while avoiding the vanishing gradient problem. This architecture has been highly successful in various computer vision tasks, including image classification, object detection, and image segmentation.","metadata":{}},{"cell_type":"code","source":"# Pre-trained Model\nimport torchvision.models as models\npretrained_model = models.resnet152(weights='IMAGENET1K_V2')\nnum_classes = 53\npretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, num_classes) ## Changing Output layer to our use case 53 classes\n\n# Cost Function and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(pretrained_model.parameters(), lr=0.001, momentum=0.9) # Momentum is Beta value \n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:26:26.973170Z","iopub.status.idle":"2024-05-21T18:26:26.973585Z","shell.execute_reply.started":"2024-05-21T18:26:26.973367Z","shell.execute_reply":"2024-05-21T18:26:26.973383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\ndef train(model, train_loader, criterion, optimizer, num_epochs=14):\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n        epoch_loss = running_loss / len(train_loader.dataset)\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:26:26.975575Z","iopub.status.idle":"2024-05-21T18:26:26.975964Z","shell.execute_reply.started":"2024-05-21T18:26:26.975784Z","shell.execute_reply":"2024-05-21T18:26:26.975801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = correct / total\n    print(f\"Accuracy: {accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:26:26.977834Z","iopub.status.idle":"2024-05-21T18:26:26.978341Z","shell.execute_reply.started":"2024-05-21T18:26:26.978084Z","shell.execute_reply":"2024-05-21T18:26:26.978105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\npretrained_model.to(device)\n# Model Training\ntrain(pretrained_model, tr_dl, criterion, optimizer)\n\n# Model Evaluation\nevaluate(pretrained_model, ts_dl)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:26:26.980057Z","iopub.status.idle":"2024-05-21T18:26:26.980469Z","shell.execute_reply.started":"2024-05-21T18:26:26.980253Z","shell.execute_reply":"2024-05-21T18:26:26.980268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy Comparison\n\n#### Accuracy in Model trained from scratch : 80 - 85 %\n\n#### Accuracy Use Pre-trained ResNet152 Model : > 95 %","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}